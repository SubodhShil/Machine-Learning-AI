{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebf6c0d",
   "metadata": {},
   "source": [
    "## Text loaders\n",
    "\n",
    "Load .txt files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75ee3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aadd74ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur molestie sapien in odio tincidunt pulvinar. Nunc tincidunt congue efficitur. Etiam dapibus molestie aliquet. Donec aliquet ullamcorper nisi, nec luctus massa aliquam in. Nunc imperdiet nisl quam, fermentum ultrices augue imperdiet at. Aenean placerat a massa pellentesque finibus. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Vestibulum quis sapien pharetra, rutrum enim sit amet, pulvinar ante. Integer at metus id ex facilisis ullamcorper sed non nisl.\\n\\nQuisque ultricies facilisis quam dignissim aliquet. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Donec nec suscipit magna. Morbi ullamcorper aliquet sem. Nulla facilisi. Donec ornare accumsan ipsum eget viverra. Mauris eleifend accumsan cursus. Proin fermentum ornare sapien. Donec ac fringilla elit. Nunc sit amet lacinia sapien, eget viverra lorem. Cras blandit, quam id vulputate facilisis, elit diam vestibulum erat, at tincidunt magna dolor nec odio. Cras et est venenatis, pharetra sapien sed, laoreet tellus. Aliquam sodales mollis nisi eget commodo. Integer mollis ipsum vel posuere volutpat. Etiam eu facilisis dolor, ac vehicula nunc.\\n\\nEtiam vel volutpat magna. Nunc sit amet ullamcorper arcu. Nam ultricies ex nec est condimentum, sed vehicula purus sodales. Sed faucibus ex id iaculis gravida. Vestibulum lorem dui, eleifend eget dui sed, vulputate sagittis mauris. Nulla lacus metus, porta sed gravida quis, vestibulum eleifend sapien. Proin lorem risus, condimentum et blandit egestas, ultrices eu ante. Donec felis leo, congue sit amet vehicula sed, finibus at justo. Aenean vehicula elit a eros hendrerit pellentesque. Etiam sit amet odio ac diam malesuada consectetur ac nec arcu. Quisque rutrum laoreet mauris id pellentesque. Fusce vulputate et risus euismod maximus. Nullam a eros iaculis velit luctus venenatis. Aliquam finibus sem in accumsan accumsan. Proin interdum molestie dui, ut consectetur risus aliquet ut. Fusce dictum iaculis sapien vitae cursus.\\n\\nMorbi neque massa, ultricies ut elit eu, bibendum rutrum eros. Cras at convallis ex. Duis cursus, tellus in maximus iaculis, massa ligula feugiat tellus, non scelerisque magna mi nec lorem. Mauris faucibus, dui commodo interdum consectetur, est libero euismod arcu, eu dictum enim elit sed risus. Praesent gravida rhoncus ligula nec ultricies. Vestibulum sit amet massa congue, consequat ipsum vel, consequat felis. Vestibulum non consectetur tortor. Integer ac leo vestibulum nulla hendrerit pretium sit amet at ligula. Nunc a venenatis diam. Nullam convallis sit amet quam sit amet elementum. Nunc nec lectus enim. Donec tincidunt eros ante, non hendrerit massa fermentum viverra. In sodales nulla ut quam sodales, at venenatis nisi consequat. Fusce ipsum orci, finibus vel sem vel, posuere convallis felis. Curabitur non nisl ac tortor faucibus vehicula ut placerat lorem.\\n\\nInteger venenatis nisi blandit, laoreet massa in, pulvinar libero. Sed porttitor varius lacus, et ullamcorper magna posuere at. Maecenas commodo mauris hendrerit diam varius, ut vehicula odio pretium. Donec id justo lacus. Pellentesque quis metus non ligula auctor luctus quis sed nunc. Maecenas a tincidunt lacus. Praesent magna magna, cursus id pretium sed, scelerisque quis velit. Nulla facilisi. Aenean posuere mauris a orci condimentum, at lacinia diam bibendum. Curabitur ultrices at turpis ac viverra. Ut interdum sed est non consequat. Pellentesque eu posuere velit. Quisque viverra gravida risus, non porta lacus.\\n\\nNunc porta sagittis orci vel rhoncus. Maecenas et tortor id massa sollicitudin molestie. Integer ultricies efficitur metus ac porttitor. Sed non faucibus sem. Pellentesque ac blandit orci, quis sagittis neque. Proin augue massa, consequat eu semper scelerisque, pellentesque vel orci. In laoreet tortor id urna congue, vehicula tristique turpis consequat. Vestibulum ligula ante, dictum ac velit sed, suscipit porttitor eros. Vestibulum ullamcorper sagittis iaculis. Maecenas tincidunt gravida ipsum. Morbi fermentum at turpis quis mollis. Nam porta ex eu justo hendrerit, sit amet interdum augue convallis. In neque nunc, imperdiet ac dolor eget, mollis semper nunc. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; In nisl eros, tincidunt eu enim vitae, tincidunt maximus mi. Curabitur leo ipsum, blandit ut metus a, mollis condimentum quam.\\n\\nFusce cursus, magna in porta ultrices, leo nunc porttitor massa, faucibus interdum ante justo vitae libero. Etiam posuere blandit tortor, at mattis mauris bibendum non. Integer a nibh accumsan, finibus nunc ut, pulvinar dolor. Cras ac ante tempor, iaculis felis nec, lacinia diam. Vestibulum sapien nibh, congue aliquet semper at, imperdiet eget ante. Vivamus rhoncus nunc vitae nulla congue mattis. Mauris dignissim imperdiet massa sit amet porta. Donec eu diam sit amet nibh lacinia consectetur.\\n\\nNunc suscipit placerat dapibus. Phasellus ultrices interdum semper. Donec in augue eu ante viverra vulputate. Interdum et malesuada fames ac ante ipsum primis in faucibus. Fusce non lectus molestie, ultricies odio ac, porta augue. Proin felis orci, elementum et venenatis vitae, venenatis ut nibh. Curabitur in risus porta velit scelerisque finibus vestibulum a massa. Nam bibendum, metus eget luctus condimentum, mauris ex rhoncus orci, id tincidunt risus dolor eget libero.\\n\\nDonec et aliquam dui. Integer in mattis justo. Nullam eleifend augue mattis, pharetra nunc sit amet, sodales metus. Praesent non vehicula neque, id viverra arcu. In sollicitudin metus arcu, in tristique nisi auctor id. Sed eget nunc scelerisque, ullamcorper felis sed, lobortis lorem. Nunc sagittis lorem tellus, sit amet ornare est blandit et.\\n\\nAliquam eu lobortis odio. Maecenas condimentum semper eros luctus accumsan. Curabitur felis risus, imperdiet a placerat eget, lacinia vitae lorem. Nulla sodales fringilla tortor vestibulum dapibus. Quisque rutrum tincidunt mattis. Ut sed nulla lacus. Sed bibendum a arcu nec imperdiet. Integer congue metus a tincidunt mattis. Nunc mattis rhoncus sodales. Etiam pulvinar tellus magna, in dictum nisi elementum non. Duis in libero ut tellus finibus laoreet quis eu purus. Curabitur congue commodo arcu, eu iaculis enim venenatis at. Nam a finibus libero. Donec euismod consectetur luctus.\\n\\nPraesent quis risus ut sapien gravida hendrerit at at neque. Sed euismod eros nisl. Quisque leo mauris, malesuada eget nulla a, suscipit molestie dui. Fusce id tincidunt tellus. Morbi et turpis lobortis, fringilla lorem et, tempor sapien. Nulla convallis, augue eget lacinia finibus, diam orci hendrerit enim, et euismod ligula felis et velit. Suspendisse venenatis massa sed porta volutpat. Curabitur posuere pharetra ligula sit amet elementum. Quisque mollis fermentum nibh. Aenean sit amet molestie ex. Aenean commodo mattis nulla, et bibendum elit facilisis ut. Suspendisse sed tortor justo.\\n\\nNulla facilisi. Ut finibus, enim eu varius aliquam, diam diam imperdiet nibh, vitae laoreet velit dui quis nisl. Phasellus enim lacus, aliquam et consectetur in, facilisis eget lectus. In laoreet elit nec ligula feugiat consequat. Duis iaculis nulla mauris, sed consectetur est consequat non. Aliquam ut interdum neque, non vestibulum orci. Curabitur ultricies velit ipsum, non accumsan justo ornare et.\\n\\nPraesent semper odio eget eros venenatis consectetur. Ut aliquet neque dignissim, interdum odio vitae, volutpat diam. Proin orci metus, gravida id risus quis, imperdiet efficitur justo. Quisque elementum turpis ut tempus maximus. Nam ut feugiat velit, eget aliquam justo. Suspendisse placerat massa eget dolor rutrum gravida. Nunc in sagittis mi. Pellentesque ut sem at risus varius feugiat. Maecenas viverra ultrices lectus, eu mattis urna. Morbi eu augue semper, posuere tortor faucibus, venenatis mi.\\n\\nIn urna augue, tristique sed pulvinar in, ornare id ante. Vivamus tempor nulla quis vulputate semper. Nulla facilisi. Nunc iaculis tellus eleifend massa varius semper nec at augue. Aenean porta metus vitae tristique mattis. Phasellus ultricies condimentum nunc, ac egestas ipsum tincidunt a. Aenean lacinia tincidunt semper. Nunc in ipsum massa. Suspendisse potenti. Vivamus quis consectetur ex. In hac habitasse platea dictumst. Aenean maximus mollis pretium. Nulla iaculis nibh libero, sed condimentum augue fringilla quis. Aliquam rutrum rhoncus elit id tristique.\\n\\nNullam ut massa cursus, volutpat libero sed, eleifend turpis. Aliquam non pellentesque turpis, eu lobortis justo. Sed rhoncus dignissim lorem, eu porttitor ipsum. Quisque tempus gravida nunc, nec vestibulum erat ultricies id. Nam eget vestibulum enim. Mauris iaculis accumsan molestie. Nulla dictum turpis ac nisi condimentum ultrices. Praesent tristique neque vitae massa mattis dictum. Morbi porta, ante nec ultricies sagittis, neque justo cursus erat, lacinia laoreet enim est eget velit. Duis eu arcu luctus, eleifend mauris sed, mollis nibh.\\n\\nMauris id lectus ac libero posuere bibendum. Maecenas rutrum nibh cursus gravida egestas. Aenean lobortis lacus lacus, at mattis augue gravida at. Nullam ullamcorper purus eleifend justo commodo, interdum posuere leo bibendum. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed nulla purus, luctus ac quam at, aliquam porttitor urna. Vestibulum vel euismod sapien. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Cras ullamcorper purus finibus, gravida quam ac, suscipit erat. Phasellus maximus dolor lectus, aliquam rutrum ligula convallis a.\\n\\nAliquam dignissim tempus massa, eu tempor sem pretium et. Nunc accumsan tincidunt mollis. Aenean hendrerit volutpat nisl, a accumsan nulla dictum eu. Sed condimentum diam eu ex aliquam, eget pellentesque lectus mattis. Fusce imperdiet mauris sit amet odio cursus rhoncus. Nulla maximus velit vel augue gravida, ut vestibulum nulla imperdiet. Cras ac lectus vitae leo lobortis convallis. Integer suscipit convallis lectus, id pretium sem scelerisque ac. Praesent id justo est. Integer tempor luctus nibh, in posuere velit viverra in.\\n\\nSuspendisse enim dui, fringilla a viverra eu, cursus a ligula. Aliquam maximus, nisl luctus cursus molestie, eros turpis fringilla erat, vel pulvinar erat orci vel nunc. Vivamus ultricies odio dui, vehicula aliquet sapien viverra eu. Nunc bibendum rutrum arcu sit amet sodales. Quisque placerat ipsum leo, et tincidunt odio facilisis id. Nam sagittis convallis pulvinar. In lacus lorem, gravida eu vehicula eu, tincidunt eget lectus. In consequat sem a libero lacinia, in sollicitudin erat tempus. In hac habitasse platea dictumst. Nullam aliquet, enim ut iaculis sollicitudin, diam lacus feugiat ligula, nec volutpat eros metus sit amet mi.\\n\\nMorbi at congue turpis. Nullam finibus convallis accumsan. Phasellus in lectus vel est interdum tempus ac ut purus. Maecenas pulvinar sagittis malesuada. Aliquam erat volutpat. Phasellus non purus eget lacus luctus eleifend. Vivamus et massa vitae turpis semper porttitor a vitae ex. Integer dignissim urna a neque iaculis, ac convallis sapien tincidunt. Curabitur accumsan luctus felis.\\n\\nIn condimentum aliquet ligula consequat varius. Sed pulvinar nunc arcu, pellentesque volutpat ex viverra et. Nulla a turpis a magna ultrices suscipit. Quisque in ante pretium, consequat nisl eget, consectetur augue. Maecenas congue interdum ipsum non suscipit. Nulla lacinia odio sit amet elit vestibulum, quis aliquam urna euismod. Donec pulvinar magna ipsum, eget consequat diam tincidunt nec. Phasellus pulvinar pellentesque eros at interdum.\\n\\nInteger interdum vestibulum elit quis finibus. Proin pellentesque tellus enim, quis convallis justo pharetra a. Duis blandit lorem ante, sit amet consequat eros efficitur et. Cras quis ipsum eget neque dignissim sollicitudin a vitae neque. Nunc dapibus urna quam, aliquam auctor felis auctor nec. Ut ex nulla, tempor nec felis vitae, dapibus porttitor ex. Nullam condimentum, libero non faucibus eleifend, ipsum lacus malesuada nisl, et posuere est tortor sit amet lorem.\\n\\nSed mollis euismod ante, non varius orci fermentum ac. Sed pulvinar a turpis sed rutrum. Nulla in tempus massa. Ut sagittis, orci vel bibendum scelerisque, libero felis fringilla ante, in mattis orci velit ut leo. Aliquam nec nulla et velit ornare commodo. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Aenean ut sem aliquet, varius mauris eget, vehicula purus. Maecenas semper ipsum mi, ac imperdiet sapien condimentum sit amet.\\n\\nSed sit amet scelerisque sapien. Nulla scelerisque purus dignissim tincidunt tincidunt. Ut quis vehicula dolor, a ullamcorper tortor. Duis nec tellus sem. Donec nibh nulla, elementum ultricies pellentesque eu, finibus ac dolor. Aliquam vehicula, diam ut gravida viverra, urna lorem venenatis ipsum, et fringilla ex lorem nec orci. Phasellus consequat posuere neque et cursus. Donec maximus cursus nibh, non tincidunt tortor gravida eu. Sed condimentum blandit ipsum et tincidunt. Aliquam egestas eros massa, eu semper lorem dignissim vitae. Etiam auctor, arcu sodales ullamcorper luctus, ligula massa posuere turpis, ut scelerisque ipsum dolor quis erat.\\n\\nMauris interdum tempor tincidunt. Praesent neque felis, facilisis vitae dolor et, tempor porta metus. Donec nisi eros, vehicula eget mattis sit amet, imperdiet ut eros. Nam dignissim sem nibh, vitae euismod nulla imperdiet nec. Etiam scelerisque sodales suscipit. Aenean lectus nisi, lacinia quis tempor eget, maximus eget elit. Ut leo lacus, fermentum ut cursus et, molestie at elit. Integer viverra nec urna eget varius. Fusce semper nibh in lectus rhoncus, nec pellentesque erat vestibulum. Phasellus in lacus consectetur, elementum nibh eu, blandit ligula. In maximus nulla ac odio feugiat, ac accumsan tortor accumsan. Proin justo justo, fermentum non iaculis lacinia, mollis non sem. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Vivamus quis cursus dui, vel accumsan augue. Nulla vel feugiat sem. Mauris at massa nec velit ornare congue et et neque.\\n\\nCurabitur ut odio vestibulum, mattis tellus eget, rutrum turpis. Etiam pretium finibus leo, a iaculis arcu placerat ut. Donec commodo, tortor id elementum ultricies, turpis dolor luctus nunc, elementum venenatis ligula magna et risus. Proin ultrices faucibus lectus, non molestie velit malesuada ut. Vestibulum eu ligula eu risus tempus faucibus nec vitae est. Sed tincidunt sed eros non placerat. Donec malesuada justo tristique scelerisque blandit. In viverra cursus nibh, sit amet vestibulum nulla bibendum ac. Duis porta tortor sed velit malesuada, sed vehicula arcu mollis. Donec tempus purus at enim vehicula, sit amet mattis quam semper. Pellentesque sit amet tincidunt nunc. Suspendisse sed semper libero, et vehicula odio. Donec tempus turpis in velit dictum tempus. Vivamus sed pretium tortor, ut scelerisque neque. Nunc facilisis ligula non sodales sollicitudin. Fusce nec auctor risus.\\n\\nAenean consectetur risus pellentesque, venenatis metus ac, facilisis tortor. Fusce consectetur aliquam dui nec interdum. Nunc quis mauris turpis. In volutpat id neque at dictum. Nunc maximus efficitur odio eu laoreet. Vivamus fringilla massa ex. In id sem in odio ullamcorper placerat.\\n\\nSed imperdiet finibus lectus. Cras pulvinar ex non ipsum tristique sagittis. Ut id eros id orci venenatis tristique vel eget lectus. Quisque consectetur lorem nec vestibulum maximus. Vestibulum iaculis congue augue in fringilla. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. In iaculis placerat elit, vel suscipit erat tincidunt vitae. Duis vitae quam et ipsum tempus tincidunt. Suspendisse dictum auctor tellus, eu scelerisque mi.\\n\\nSed eu commodo justo, id pretium purus. Duis porttitor purus ac dolor dapibus mollis. Nulla facilisi. Curabitur tincidunt purus sollicitudin nulla consequat semper. Nulla porta blandit erat et iaculis. Nulla cursus sed lorem id faucibus. Nam fermentum congue ligula, vitae placerat eros dictum sit amet. Suspendisse efficitur id magna malesuada euismod. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Nulla facilisi. Quisque nec nisl commodo, gravida elit quis, viverra erat. Nulla facilisi. Curabitur tempor, odio ac fringilla vulputate, magna risus fermentum felis, in molestie ex enim eu erat.\\n\\nNulla feugiat enim a est tempus, in lacinia ipsum tristique. Cras dapibus pharetra placerat. Nunc sed placerat urna, sed commodo mauris. Mauris porttitor eros ut accumsan auctor. Etiam at tortor orci. Morbi id vestibulum lorem. Nam condimentum mi erat, in iaculis mauris vehicula vel. Vestibulum eu justo velit. Proin ornare dictum lacus in viverra. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas.\\n\\nCras non viverra est. Suspendisse scelerisque iaculis varius. Maecenas arcu magna, ultricies in turpis nec, sodales convallis sapien. Nunc quis ipsum diam. Phasellus eget porttitor mi. Nulla suscipit, urna quis viverra pellentesque, lacus augue mattis lectus, sed scelerisque neque metus quis leo. Praesent posuere justo consequat libero convallis, sit amet pretium sapien iaculis. Cras viverra vitae nisi id auctor. Maecenas placerat metus eu elit viverra, nec tincidunt elit bibendum. Morbi pretium, diam a consequat congue, ante dui bibendum diam, eget convallis sapien turpis non lectus. Aenean sit amet viverra ipsum. Aliquam sed tortor et odio molestie tincidunt et nec arcu. Cras interdum purus lorem, sit amet molestie massa elementum eu. Nunc convallis, arcu vitae ornare cursus, nulla est elementum lacus, eu lobortis quam mi non velit. Mauris mi urna, aliquam non purus eget, ultrices lobortis turpis. Sed sagittis sagittis est sit amet mattis.\\n\\nEtiam nec ipsum lectus. Aenean quis est luctus lectus efficitur hendrerit. Donec a scelerisque lorem, hendrerit molestie urna. Nulla nec malesuada metus. Praesent dapibus, erat id cursus vehicula, ex lacus malesuada magna, vel ornare elit enim lobortis lectus. Nullam cursus efficitur eros, quis blandit magna cursus ac. Pellentesque egestas eget magna non accumsan. Nulla et lorem aliquet, aliquam magna in, vehicula enim. Integer volutpat et nisi et consectetur. Aliquam eu feugiat nisl.\\n\\nUt maximus sit amet enim vel feugiat. Ut volutpat placerat enim ac gravida. Quisque viverra hendrerit risus. Nam eros tellus, congue ut nisi sed, tincidunt hendrerit urna. Praesent eu sagittis ligula. Pellentesque a elit lectus. Aenean sollicitudin leo diam, at gravida neque gravida nec. Sed mollis tincidunt elit sed interdum. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Proin eu lectus aliquet, vehicula enim a, ornare lectus. Proin in arcu rutrum, mollis massa consequat, porttitor mauris. Mauris nisi purus, finibus non mauris in, tincidunt consequat lacus.\\n\\nMaecenas suscipit leo sem, venenatis faucibus ipsum volutpat quis. Donec malesuada, enim non lobortis lobortis, turpis tellus dignissim massa, pharetra pulvinar dui augue non augue. Nunc sit amet arcu at velit euismod posuere in non lacus. Nunc malesuada rutrum eros, ac euismod mauris suscipit condimentum. Pellentesque blandit, quam ut rhoncus rhoncus, sapien neque aliquam elit, ut auctor eros orci ac lacus. Nam leo leo, tempus sed libero sit amet, suscipit consequat eros. Aliquam fringilla sapien eu dui pretium ornare. Sed sit amet leo mauris.\\n\\nCras dictum diam sit amet nulla facilisis, eu convallis ex dignissim. Quisque vestibulum est tortor, at porttitor lectus mollis id. Sed sit amet scelerisque arcu. Nulla mollis dolor enim, et consequat elit posuere eu. Morbi nec sagittis eros, et viverra enim. Mauris feugiat viverra libero ac elementum. Mauris auctor turpis quis nisl auctor, sit amet porttitor libero tincidunt.\\n\\nProin gravida mattis pulvinar. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Nam cursus nibh ut diam semper tristique. Duis ac dui nec mauris sodales mollis in at ante. In hac habitasse platea dictumst. Duis tristique sollicitudin neque sed dapibus. Aenean eget pretium justo. Integer in magna nulla. Praesent eleifend, ipsum sed elementum interdum, urna nulla sagittis libero, non venenatis libero mauris et eros. Suspendisse quis ex sit amet justo tincidunt luctus. Integer elementum justo quis est pharetra, at lobortis dolor convallis. Pellentesque vel nisi enim. Aliquam vulputate sit amet sem et malesuada. Vestibulum elementum mattis felis, non sodales risus commodo non. Donec egestas massa augue, sed pretium tortor porta ac. Nam et hendrerit turpis.\\n\\nNulla elit lacus, hendrerit ac ipsum sed, luctus porta massa. Quisque nulla est, mattis ac dictum id, congue in leo. Etiam eget nunc tincidunt, iaculis dui ac, pretium dolor. Curabitur non ornare massa. Etiam feugiat tortor vitae erat pharetra volutpat. Donec mollis rutrum metus a eleifend. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. In molestie vitae sem pulvinar finibus. Aenean accumsan tortor ac justo pretium, ut sagittis magna molestie. Donec pretium malesuada ligula. Maecenas semper et enim vel semper.\\n\\nVivamus felis nibh, porta id nunc vel, molestie tincidunt leo. Aenean a mi quis magna ornare maximus eu nec sem. Nunc ut augue ac lacus rutrum dictum. Sed magna orci, volutpat pellentesque facilisis et, aliquam vel erat. Interdum et malesuada fames ac ante ipsum primis in faucibus. Phasellus sagittis nisi id arcu accumsan fringilla. Quisque aliquam tincidunt felis non congue. Praesent laoreet vitae risus sed ultrices. Etiam luctus vulputate eros, sit amet blandit magna vulputate quis. Mauris ex augue, blandit sit amet auctor et, egestas ut purus. Etiam eleifend ornare dolor sit amet sagittis.\\n\\nNam elementum tortor non sapien rutrum dignissim. Curabitur sed felis nec lacus laoreet hendrerit. Proin dignissim, eros at varius condimentum, leo lacus suscipit leo, vel ornare felis odio porta purus. Morbi quis tempus neque, non efficitur tortor. Vestibulum mi libero, facilisis nec laoreet non, auctor a sem. Morbi auctor ante eu velit accumsan, sit amet varius erat molestie. Nulla ultricies lacinia arcu, vitae efficitur velit rutrum vitae. Ut quis quam elit. Aliquam eu convallis lectus. Nullam et laoreet ex. Fusce ante est, tempor sit amet lacus sodales, cursus gravida magna. Vestibulum sagittis consequat nisl. Curabitur id volutpat sapien. Phasellus molestie viverra nibh a venenatis. Nulla pharetra ultrices tellus et tincidunt.\\n\\nAenean a erat egestas, elementum ipsum non, semper mauris. Duis tempor pretium ex vel feugiat. Donec cursus erat augue, vitae volutpat ipsum condimentum sit amet. Donec bibendum tincidunt magna, non efficitur ipsum pretium vel. Vestibulum et mauris bibendum, interdum tellus sit amet, iaculis purus. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia curae; Duis et lectus eleifend ligula scelerisque suscipit. Vestibulum eu mauris vel arcu dictum condimentum. Etiam volutpat lorem et aliquet varius. Vestibulum eget augue nec quam tristique molestie. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Duis viverra pulvinar felis quis iaculis. Praesent non cursus lorem.\\n\\nDuis urna neque, cursus non dui a, euismod hendrerit est. Nam vel sagittis lacus, vel vehicula mi. In hac habitasse platea dictumst. Praesent sit amet elementum lorem. Nam elementum et nibh non luctus. Donec libero felis, lobortis eu aliquam sed, faucibus ut enim. Nunc nec magna quis enim commodo ultrices. Vivamus aliquam orci ac dictum auctor. Praesent ut posuere tellus, quis molestie turpis. In hac habitasse platea dictumst. Mauris laoreet nibh eu nunc volutpat semper dictum lacinia nibh. Cras non fermentum magna. Maecenas tempor finibus molestie.\\n\\nNullam ex orci, elementum eu eleifend eu, scelerisque non enim. Cras maximus dolor eget metus interdum posuere. Nunc tincidunt, erat sollicitudin accumsan vulputate, dui sapien ultricies nisl, non interdum augue quam sed augue. Donec pellentesque ex lorem, elementum cursus nibh condimentum in. Suspendisse eget lectus vulputate, dictum tellus at, placerat libero. Nullam pellentesque mauris at molestie dignissim. Suspendisse potenti. Cras tempor lectus at interdum venenatis. Nulla id venenatis libero, a fermentum erat. Nulla gravida tortor ac quam varius suscipit. Pellentesque finibus sem nisl, et vulputate orci vehicula ac. Proin dignissim ante tortor, sit amet scelerisque erat tincidunt ac. Cras finibus nibh felis, et blandit tortor lacinia at. Ut congue turpis vitae urna tincidunt imperdiet id et lorem. Morbi lobortis ultricies sagittis.\\n\\nDonec nec dapibus augue. Aenean suscipit interdum nisi vel porta. Praesent in justo consectetur, sollicitudin massa vel, suscipit tortor. Pellentesque luctus arcu augue, porta tincidunt ipsum tincidunt in. Curabitur aliquet porta nisl, non commodo nulla finibus quis. Donec lacus est, dapibus eu posuere sed, sollicitudin ac orci. Nam elementum magna id quam convallis volutpat.\\n\\nDuis gravida fermentum posuere. Nunc hendrerit luctus sem, vitae imperdiet leo hendrerit sit amet. Nunc elementum libero hendrerit, sodales ex non, gravida tellus. Sed egestas tempor dignissim. Nunc eros nibh, aliquam euismod tempus in, interdum sed purus. Praesent porta pharetra accumsan. Proin nec blandit orci. Nulla ornare rutrum erat sit amet efficitur. Phasellus ut interdum nisl. Integer mattis, nisi sit amet scelerisque tristique, odio ipsum accumsan quam, sit amet consequat enim nunc ut dolor. Cras in fringilla diam, at congue ex. Nulla aliquet est imperdiet, pulvinar lectus eu, luctus nisl. Donec fringilla tincidunt odio, a rutrum lorem placerat vitae. Donec orci nibh, condimentum eu libero sed, convallis pellentesque elit.\\n\\nSuspendisse semper tellus vel facilisis bibendum. Sed vulputate metus eu arcu ultrices tempus. Nam fermentum, libero in bibendum rhoncus, ex metus feugiat dui, volutpat egestas sem odio id augue. In sit amet massa at mauris sodales sodales et a tortor. Cras laoreet leo vitae porttitor facilisis. Proin sodales scelerisque quam, sed aliquet lectus accumsan et. Vestibulum in dui nisl. Cras feugiat erat nisl, eu dictum elit varius sit amet. Aenean massa diam, efficitur sed ante et, varius tristique tellus. Aenean scelerisque sed velit et malesuada. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Suspendisse et iaculis mauris, non ultricies ipsum. In consequat sem quis nisl sollicitudin, in molestie eros semper.\\n\\nAliquam vitae auctor lectus. Nam purus nulla, efficitur vitae tortor nec, fermentum tempus quam. Mauris tortor neque, laoreet nec sagittis nec, ultrices nec tortor. Morbi mattis bibendum felis, non pulvinar sem aliquet vitae. Proin at ornare justo. Integer scelerisque justo nec metus cursus suscipit. Fusce sit amet neque feugiat, feugiat magna vitae, euismod metus.\\n\\nCras eleifend vulputate sapien eu hendrerit. Ut sed libero tincidunt mauris sagittis interdum sit amet sit amet ipsum. Donec lobortis erat eu luctus vehicula. Nulla vitae molestie felis. Nunc nec eros neque. Vestibulum non ullamcorper lectus. Nam est turpis, pharetra ac porttitor eget, interdum et augue. Sed feugiat tortor non magna fringilla, id condimentum ante egestas.\\n\\nAenean eget risus id est sagittis consectetur condimentum ut neque. Sed at malesuada ligula, sed convallis sem. In porta maximus porttitor. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi gravida felis tempor urna dignissim, in consequat diam rhoncus. Suspendisse elit tortor, aliquam at venenatis commodo, lobortis eu ex. Quisque massa erat, congue ut accumsan vel, lobortis vitae magna. Vivamus sit amet luctus libero. Quisque id porttitor metus, lacinia porttitor elit. Nulla ornare lorem vitae imperdiet ullamcorper.\\n\\nSed hendrerit venenatis nibh, non ultrices erat maximus id. Fusce mollis leo nec arcu pretium mollis. Maecenas convallis rhoncus augue sed pretium. Pellentesque quis lacinia nunc. Nullam a leo consequat, placerat eros venenatis, venenatis turpis. Fusce non feugiat nulla. Quisque ex libero, convallis sit amet suscipit quis, viverra nec justo. Ut blandit ante vel odio lobortis, vel finibus lorem aliquam. Donec tempor sagittis risus at iaculis.\\n\\nCras sodales orci a rhoncus accumsan. Nulla bibendum, augue eu consectetur rhoncus, ex purus interdum magna, nec dictum turpis odio et orci. Integer at convallis eros, in sollicitudin odio. Sed vitae fringilla lorem. Morbi nec malesuada augue. Vestibulum lectus turpis, sollicitudin vel enim nec, scelerisque iaculis erat. Maecenas ut lorem eu ex bibendum porta vel vel orci. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Suspendisse potenti.\\n\\nQuisque a auctor libero, eu rutrum felis. Mauris quis posuere nulla. Pellentesque ut metus ut dui finibus dapibus et et ex. Fusce facilisis facilisis mi, at ultrices ex euismod sed. Duis et sapien eget ex sodales ullamcorper a id velit. Quisque id augue tortor. Mauris fringilla ante sed dolor blandit dictum. Donec tincidunt, enim vel venenatis sagittis, mauris mi ullamcorper ipsum, quis iaculis lacus dui sed odio. Donec ac ligula et lorem pulvinar dignissim sed sit amet lectus. Integer quis urna iaculis, rhoncus arcu sit amet, vulputate neque. Nam blandit sollicitudin rutrum. In gravida maximus dui vitae dignissim.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadObj = loader.load()\n",
    "loadObj[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8e19d",
   "metadata": {},
   "source": [
    "## Loading PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6a07d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdfLoader = PyPDFLoader(\"Demo2_last.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfLoaderObj = pdfLoader.load()\n",
    "pages = len(pdfLoaderObj)\n",
    "\n",
    "all_contents = \"\"\n",
    "for page in range(pages):\n",
    "    all_contents += pdfLoaderObj[page].page_content + \"\\n\\n\"\n",
    "    # print(pdfLoaderObj[page].page_content)\n",
    "\n",
    "print(all_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a382515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdfLoaderObj[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c84f2b",
   "metadata": {},
   "source": [
    "## Web based loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0f49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Overview - Docs by LangChainSkip to main contentOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KOSS (v1-alpha)LangChain and LangGraphProvidersIntegration packagesOpenAIAnthropicGoogleOverviewChatGoogleGenerativeAIChatVertexAIGoogleGenerativeAIEmbeddingsVertexAIEmbeddingsAWSHugging FaceMicrosoftAll integrationsIntegrations by componentChat modelsTools and toolkitsRetrieversText splittersEmbedding modelsVector storesDocument loadersKey-value storesOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationGoogleOverviewLangChainLangGraphIntegrationsLearnReferenceContributingLangChainLangGraphIntegrationsLearnReferenceContributingGitHubForumOn this pageGoogle Generative AI (Gemini API & AI Studio)Chat ModelsEmbedding ModelsLLMsGoogle CloudChat ModelsVertex AIAnthropic on Vertex AI Model GardenLlama on Vertex AI Model GardenMistral on Vertex AI Model GardenGemma local from Hugging FaceGemma local from KaggleGemma on Vertex AI Model GardenVertex AI image captioningVertex AI image editorVertex AI image generatorVertex AI visual QnALLMsVertex AI Model GardenGemma local from Hugging FaceGemma local from KaggleGemma on Vertex AI Model GardenVertex AI image captioningEmbedding ModelsVertex AIDocument LoadersAlloyDB for PostgreSQLBigQueryBigtableCloud SQL for MySQLCloud SQL for SQL ServerCloud SQL for PostgreSQLCloud StorageCloud Vision loaderEl Carro for Oracle WorkloadsFirestore (Native Mode)Firestore (Datastore Mode)Memorystore for RedisSpannerSpeech-to-TextDocument TransformersDocument AIGoogle TranslateVector StoresAlloyDB for PostgreSQLBigQuery Vector SearchMemorystore for RedisSpannerFirestore (Native Mode)Cloud SQL for MySQLCloud SQL for PostgreSQLVertex AI Vector SearchRetrieversVertex AI SearchDocument AI WarehouseToolsText-to-SpeechGoogle DriveGoogle FinanceGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle TrendsToolkitsGmailMCP ToolboxInstallationGetting StartedCallbacksVertex AI callback handlerEvaluatorsVertexPairWiseStringEvaluatorVertexStringEvaluatorOther Google ProductsDocument LoadersGoogle DriveVector StoresScaNN (Local Index)RetrieversGoogle DriveToolsGoogle DriveGoogle FinanceGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle TrendsToolkitsGmailChat LoadersGmail3rd Party IntegrationsSearchApiSerpApiSerper.devYouTubeYouTube Search ToolYouTube Audio LoaderYouTube Transcripts LoaderProvidersGoogleOverviewCopy pageCopy pageAll functionality related to Google Cloud, Google Gemini and other Google products.\\n\\nGoogle Generative AI (Gemini API & AI Studio): Access Google Gemini models directly via the Gemini API. Use Google AI Studio for rapid prototyping and get started quickly with the langchain-google-genai package. This is often the best starting point for individual developers.\\nGoogle Cloud (Vertex AI & other services): Access Gemini models, Vertex AI Model Garden and a wide range of cloud services (databases, storage, document AI, etc.) via the Google Cloud Platform. Use the langchain-google-vertexai package for Vertex AI models and specific packages (e.g., langchain-google-cloud-sql-pg, langchain-google-community) for other cloud services. This is ideal for developers already using Google Cloud or needing enterprise features like MLOps, specific model tuning or enterprise support.\\n\\nSee Google’s guide on migrating from the Gemini API to Vertex AI for more details on the differences.\\nIntegration packages for Gemini models and the Vertex AI platform are maintained in\\nthe langchain-google repository.\\nYou can find a host of LangChain integrations with other Google APIs and services in the\\ngoogleapis\\nGithub organization and the langchain-google-community package.\\n\\u200bGoogle Generative AI (Gemini API & AI Studio)\\nAccess Google Gemini models directly using the Gemini API, best suited for rapid development and experimentation. Gemini models are available in Google AI Studio.\\npipuvCopypip install -U langchain-google-genai\\n\\nStart for free and get your API key from Google AI Studio.\\nCopyexport GOOGLE_API_KEY=\"YOUR_API_KEY\"\\n\\n\\u200bChat Models\\nUse the ChatGoogleGenerativeAI class to interact with Gemini models. See\\ndetails in this guide.\\nCopyfrom langchain_google_genai import ChatGoogleGenerativeAI\\nfrom langchain_core.messages import HumanMessage\\n\\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\\n\\n# Simple text invocation\\nresult = llm.invoke(\"Sing a ballad of LangChain.\")\\nprint(result.content)\\n\\n# Multimodal invocation with gemini-pro-vision\\nmessage = HumanMessage(\\n    content=[\\n        {\\n            \"type\": \"text\",\\n            \"text\": \"What\\'s in this image?\",\\n        },\\n        {\"type\": \"image_url\", \"image_url\": \"https://picsum.photos/seed/picsum/200/300\"},\\n    ]\\n)\\nresult = llm.invoke([message])\\nprint(result.content)\\n\\nThe image_url can be a public URL, a GCS URI (gs://...), a local file path, a base64 encoded image string (data:image/png;base64,...), or a PIL Image object.\\n\\u200bEmbedding Models\\nGenerate text embeddings using models like gemini-embedding-001 with the GoogleGenerativeAIEmbeddings class.\\nSee a usage example.\\nCopyfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\\n\\nembeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\\nvector = embeddings.embed_query(\"What are embeddings?\")\\nprint(vector[:5])\\n\\n\\u200bLLMs\\nAccess the same Gemini models using the (legacy) LLM\\ninterface with the GoogleGenerativeAI class.\\nSee a usage example.\\nCopyfrom langchain_google_genai import GoogleGenerativeAI\\n\\nllm = GoogleGenerativeAI(model=\"gemini-2.5-flash\")\\nresult = llm.invoke(\"Sing a ballad of LangChain.\")\\nprint(result)\\n\\n\\u200bGoogle Cloud\\nAccess Gemini models, Vertex AI Model Garden and other Google Cloud services via Vertex AI and specific cloud integrations.\\nVertex AI models require the langchain-google-vertexai package. Other services might require additional packages like langchain-google-community, langchain-google-cloud-sql-pg, etc.\\npipuvCopypip install langchain-google-vertexai\\n# pip install langchain-google-community[...] # For other services\\n\\nGoogle Cloud integrations typically use Application Default Credentials (ADC). Refer to the Google Cloud authentication documentation for setup instructions (e.g., using gcloud auth application-default login).\\n\\u200bChat Models\\n\\u200bVertex AI\\nAccess chat models like Gemini via the Vertex AI platform.\\nSee a usage example.\\nCopyfrom langchain_google_vertexai import ChatVertexAI\\n\\n\\u200bAnthropic on Vertex AI Model Garden\\nSee a usage example.\\nCopyfrom langchain_google_vertexai.model_garden import ChatAnthropicVertex\\n\\n\\u200bLlama on Vertex AI Model Garden\\nCopyfrom langchain_google_vertexai.model_garden_maas.llama import VertexModelGardenLlama\\n\\n\\u200bMistral on Vertex AI Model Garden\\nCopyfrom langchain_google_vertexai.model_garden_maas.mistral import VertexModelGardenMistral\\n\\n\\u200bGemma local from Hugging Face\\n\\nLocal Gemma model loaded from HuggingFace. Requires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.gemma import GemmaChatLocalHF\\n\\n\\u200bGemma local from Kaggle\\n\\nLocal Gemma model loaded from Kaggle. Requires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.gemma import GemmaChatLocalKaggle\\n\\n\\u200bGemma on Vertex AI Model Garden\\n\\nRequires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.gemma import GemmaChatVertexAIModelGarden\\n\\n\\u200bVertex AI image captioning\\n\\nImplementation of the Image Captioning model as a chat. Requires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.vision_models import VertexAIImageCaptioningChat\\n\\n\\u200bVertex AI image editor\\n\\nGiven an image and a prompt, edit the image. Currently only supports mask-free editing. Requires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.vision_models import VertexAIImageEditorChat\\n\\n\\u200bVertex AI image generator\\n\\nGenerates an image from a prompt. Requires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.vision_models import VertexAIImageGeneratorChat\\n\\n\\u200bVertex AI visual QnA\\n\\nChat implementation of a visual QnA model. Requires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.vision_models import VertexAIVisualQnAChat\\n\\n\\u200bLLMs\\nYou can also use the (legacy) string-in, string-out LLM\\ninterface.\\n\\u200bVertex AI Model Garden\\nAccess Gemini, and hundreds of OSS models via Vertex AI Model Garden service. Requires langchain-google-vertexai.\\nSee a usage example.\\nCopyfrom langchain_google_vertexai import VertexAIModelGarden\\n\\n\\u200bGemma local from Hugging Face\\n\\nLocal Gemma model loaded from HuggingFace. Requires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.gemma import GemmaLocalHF\\n\\n\\u200bGemma local from Kaggle\\n\\nLocal Gemma model loaded from Kaggle. Requires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.gemma import GemmaLocalKaggle\\n\\n\\u200bGemma on Vertex AI Model Garden\\n\\nRequires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.gemma import GemmaVertexAIModelGarden\\n\\n\\u200bVertex AI image captioning\\n\\nImplementation of the Image Captioning model as an LLM. Requires langchain-google-vertexai.\\n\\nCopyfrom langchain_google_vertexai.vision_models import VertexAIImageCaptioning\\n\\n\\u200bEmbedding Models\\n\\u200bVertex AI\\nGenerate embeddings using models deployed on Vertex AI. Requires langchain-google-vertexai.\\nSee a usage example.\\nCopyfrom langchain_google_vertexai import VertexAIEmbeddings\\n\\n\\u200bDocument Loaders\\nLoad documents from various Google Cloud sources.\\n\\u200bAlloyDB for PostgreSQL\\n\\nGoogle Cloud AlloyDB is a fully managed PostgreSQL-compatible database service.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-alloydb-pg\\n\\nSee usage example.\\nCopyfrom langchain_google_alloydb_pg import AlloyDBLoader # AlloyDBEngine also available\\n\\n\\u200bBigQuery\\n\\nGoogle Cloud BigQuery is a serverless data warehouse.\\n\\nInstall with BigQuery dependencies:\\npipuvCopypip install langchain-google-community[bigquery]\\n\\nSee a usage example.\\nCopyfrom langchain_google_community import BigQueryLoader\\n\\n\\u200bBigtable\\n\\nGoogle Cloud Bigtable is a fully managed NoSQL Big Data database service.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-bigtable\\n\\nSee usage example.\\nCopyfrom langchain_google_bigtable import BigtableLoader\\n\\n\\u200bCloud SQL for MySQL\\n\\nGoogle Cloud SQL for MySQL is a fully-managed MySQL database service.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-cloud-sql-mysql\\n\\nSee usage example.\\nCopyfrom langchain_google_cloud_sql_mysql import MySQLLoader # MySQLEngine also available\\n\\n\\u200bCloud SQL for SQL Server\\n\\nGoogle Cloud SQL for SQL Server is a fully-managed SQL Server database service.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-cloud-sql-mssql\\n\\nSee usage example.\\nCopyfrom langchain_google_cloud_sql_mssql import MSSQLLoader # MSSQLEngine also available\\n\\n\\u200bCloud SQL for PostgreSQL\\n\\nGoogle Cloud SQL for PostgreSQL is a fully-managed PostgreSQL database service.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-cloud-sql-pg\\n\\nSee usage example.\\nCopyfrom langchain_google_cloud_sql_pg import PostgresLoader # PostgresEngine also available\\n\\n\\u200bCloud Storage\\n\\nCloud Storage is a managed service for storing unstructured data.\\n\\nInstall with GCS dependencies:\\npipuvCopypip install langchain-google-community[gcs]\\n\\nLoad from a directory or a specific file:\\nSee directory usage example.\\nCopyfrom langchain_google_community import GCSDirectoryLoader\\n\\nSee file usage example.\\nCopyfrom langchain_google_community import GCSFileLoader\\n\\n\\u200bCloud Vision loader\\nLoad data using Google Cloud Vision API.\\nInstall with Vision dependencies:\\npipuvCopypip install langchain-google-community[vision]\\n\\nCopyfrom langchain_google_community.vision import CloudVisionLoader\\n\\n\\u200bEl Carro for Oracle Workloads\\n\\nGoogle El Carro Oracle Operator runs Oracle databases in Kubernetes.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-el-carro\\n\\nSee usage example.\\nCopyfrom langchain_google_el_carro import ElCarroLoader\\n\\n\\u200bFirestore (Native Mode)\\n\\nGoogle Cloud Firestore is a NoSQL document database.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-firestore\\n\\nSee usage example.\\nCopyfrom langchain_google_firestore import FirestoreLoader\\n\\n\\u200bFirestore (Datastore Mode)\\n\\nGoogle Cloud Firestore in Datastore mode.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-datastore\\n\\nSee usage example.\\nCopyfrom langchain_google_datastore import DatastoreLoader\\n\\n\\u200bMemorystore for Redis\\n\\nGoogle Cloud Memorystore for Redis is a fully managed Redis service.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-memorystore-redis\\n\\nSee usage example.\\nCopyfrom langchain_google_memorystore_redis import MemorystoreDocumentLoader\\n\\n\\u200bSpanner\\n\\nGoogle Cloud Spanner is a fully managed, globally distributed relational database service.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-spanner\\n\\nSee usage example.\\nCopyfrom langchain_google_spanner import SpannerLoader\\n\\n\\u200bSpeech-to-Text\\n\\nGoogle Cloud Speech-to-Text transcribes audio files.\\n\\nInstall with Speech-to-Text dependencies:\\npipuvCopypip install langchain-google-community[speech]\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_google_community import SpeechToTextLoader\\n\\n\\u200bDocument Transformers\\nTransform documents using Google Cloud services.\\n\\u200bDocument AI\\n\\nGoogle Cloud Document AI is a Google Cloud\\nservice that transforms unstructured data from documents into structured data, making it easier\\nto understand, analyze, and consume.\\n\\nWe need to set up a GCS bucket and create your own OCR processor\\nThe GCS_OUTPUT_PATH should be a path to a folder on GCS (starting with gs://)\\nand a processor name should look like projects/PROJECT_NUMBER/locations/LOCATION/processors/PROCESSOR_ID.\\nWe can get it either programmatically or copy from the Prediction endpoint section of the Processor details\\ntab in the Google Cloud Console.\\npipuvCopypip install langchain-google-community[docai]\\n\\nSee a usage example.\\nCopyfrom langchain_core.document_loaders.blob_loaders import Blob\\nfrom langchain_google_community import DocAIParser\\n\\n\\u200bGoogle Translate\\n\\nGoogle Translate is a multilingual neural machine\\ntranslation service developed by Google to translate text, documents and websites\\nfrom one language into another.\\n\\nThe GoogleTranslateTransformer allows you to translate text and HTML with the Google Cloud Translation API.\\nFirst, we need to install the langchain-google-community with translate dependencies.\\npipuvCopypip install langchain-google-community[translate]\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_google_community import GoogleTranslateTransformer\\n\\n\\u200bVector Stores\\nStore and search vectors using Google Cloud databases and Vertex AI Vector Search.\\n\\u200bAlloyDB for PostgreSQL\\n\\nGoogle Cloud AlloyDB is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability on Google Cloud. AlloyDB is 100% compatible with PostgreSQL.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-alloydb-pg\\n\\nSee usage example.\\nCopyfrom langchain_google_alloydb_pg import AlloyDBVectorStore # AlloyDBEngine also available\\n\\n\\u200bBigQuery Vector Search\\n\\nGoogle Cloud BigQuery,\\nBigQuery is a serverless and cost-effective enterprise data warehouse in Google Cloud.\\nGoogle Cloud BigQuery Vector Search\\nBigQuery vector search lets you use GoogleSQL to do semantic search, using vector indexes for fast but approximate results, or using brute force for exact results.\\n\\n\\nIt can calculate Euclidean or Cosine distance. With LangChain, we default to use Euclidean distance.\\n\\nWe need to install several python packages.\\npipuvCopypip install google-cloud-bigquery\\n\\nSee usage example.\\nCopy# Note: BigQueryVectorSearch might be in langchain or langchain_community depending on version\\n# Check imports in the usage example.\\nfrom langchain.vectorstores import BigQueryVectorSearch # Or langchain_community.vectorstores\\n\\n\\u200bMemorystore for Redis\\n\\nVector store using Memorystore for Redis.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-memorystore-redis\\n\\nSee usage example.\\nCopyfrom langchain_google_memorystore_redis import RedisVectorStore\\n\\n\\u200bSpanner\\n\\nVector store using Cloud Spanner.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-spanner\\n\\nSee usage example.\\nCopyfrom langchain_google_spanner import SpannerVectorStore\\n\\n\\u200bFirestore (Native Mode)\\n\\nVector store using Firestore.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-firestore\\n\\nSee usage example.\\nCopyfrom langchain_google_firestore import FirestoreVectorStore\\n\\n\\u200bCloud SQL for MySQL\\n\\nVector store using Cloud SQL for MySQL.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-cloud-sql-mysql\\n\\nSee usage example.\\nCopyfrom langchain_google_cloud_sql_mysql import MySQLVectorStore # MySQLEngine also available\\n\\n\\u200bCloud SQL for PostgreSQL\\n\\nVector store using Cloud SQL for PostgreSQL.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-cloud-sql-pg\\n\\nSee usage example.\\nCopyfrom langchain_google_cloud_sql_pg import PostgresVectorStore # PostgresEngine also available\\n\\n\\u200bVertex AI Vector Search\\n\\nGoogle Cloud Vertex AI Vector Search from Google Cloud,\\nformerly known as Vertex AI Matching Engine, provides the industry’s leading high-scale\\nlow latency vector database. These vector databases are commonly\\nreferred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.\\n\\nInstall the python package:\\npipuvCopypip install langchain-google-vertexai\\n\\nSee a usage example.\\nCopyfrom langchain_google_vertexai import VectorSearchVectorStore\\n\\nWith DataStore Backend\\n\\nVector search using Datastore for document storage.\\n\\nSee usage example.\\nCopyfrom langchain_google_vertexai import VectorSearchVectorStoreDatastore\\n\\nWith GCS Backend\\n\\nAlias for VectorSearchVectorStore storing documents/index in GCS.\\n\\nCopyfrom langchain_google_vertexai import VectorSearchVectorStoreGCS\\n\\n\\u200bRetrievers\\nRetrieve information using Google Cloud services.\\n\\u200bVertex AI Search\\n\\nBuild generative AI powered search engines using Vertex AI Search.\\nfrom Google Cloud allows developers to quickly build generative AI powered search engines for customers and employees.\\n\\nSee a usage example.\\nNote: GoogleVertexAISearchRetriever is deprecated. Use the components below from langchain-google-community.\\nInstall the google-cloud-discoveryengine package for underlying access.\\npipuvCopypip install google-cloud-discoveryengine langchain-google-community\\n\\nVertexAIMultiTurnSearchRetriever\\nCopyfrom langchain_google_community import VertexAIMultiTurnSearchRetriever\\n\\nVertexAISearchRetriever\\nCopy# Note: The example code shows VertexAIMultiTurnSearchRetriever, confirm if VertexAISearchRetriever is separate or related.\\n# Assuming it might be related or a typo in the original doc:\\nfrom langchain_google_community import VertexAISearchRetriever # Verify class name if needed\\n\\nVertexAISearchSummaryTool\\nCopyfrom langchain_google_community import VertexAISearchSummaryTool\\n\\n\\u200bDocument AI Warehouse\\n\\nSearch, store, and manage documents using Document AI Warehouse.\\n\\nNote: GoogleDocumentAIWarehouseRetriever (from langchain) is deprecated. Use DocumentAIWarehouseRetriever from langchain-google-community.\\nRequires installation of relevant Document AI packages (check specific docs).\\npipuvCopypip install langchain-google-community # Add specific docai dependencies if needed\\n\\nCopyfrom langchain_google_community.documentai_warehouse import DocumentAIWarehouseRetriever\\n\\n\\u200bTools\\nIntegrate agents with various Google services.\\n\\u200bText-to-Speech\\n\\nGoogle Cloud Text-to-Speech is a Google Cloud service that enables developers to\\nsynthesize natural-sounding speech with 100+ voices, available in multiple languages and variants.\\nIt applies DeepMind’s groundbreaking research in WaveNet and Google’s powerful neural networks\\nto deliver the highest fidelity possible.\\n\\nInstall required packages:\\npipuvCopypip install google-cloud-text-to-speech langchain-google-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_google_community import TextToSpeechTool\\n\\n\\u200bGoogle Drive\\nTools for interacting with Google Drive.\\nInstall required packages:\\npipuvCopypip install google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-googledrive\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_googledrive.utilities.google_drive import GoogleDriveAPIWrapper\\nfrom langchain_googledrive.tools.google_drive.tool import GoogleDriveSearchTool\\n\\n\\u200bGoogle Finance\\nQuery financial data. Requires google-search-results package and SerpApi key.\\npipuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_finance import GoogleFinanceQueryRun\\nfrom langchain_community.utilities.google_finance import GoogleFinanceAPIWrapper\\n\\n\\u200bGoogle Jobs\\nQuery job listings. Requires google-search-results package and SerpApi key.\\npipuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_jobs import GoogleJobsQueryRun\\n# Note: Utilities might be shared, e.g., GoogleFinanceAPIWrapper was listed, verify correct utility\\n# from langchain_community.utilities.google_jobs import GoogleJobsAPIWrapper # If exists\\n\\n\\u200bGoogle Lens\\nPerform visual searches. Requires google-search-results package and SerpApi key.\\npipuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_lens import GoogleLensQueryRun\\nfrom langchain_community.utilities.google_lens import GoogleLensAPIWrapper\\n\\n\\u200bGoogle Places\\nSearch for places information. Requires googlemaps package and a Google Maps API key.\\npipuvCopypip install googlemaps langchain # Requires base langchain\\n\\nSee usage example and authorization instructions.\\nCopy# Note: GooglePlacesTool might be in langchain or langchain_community depending on version\\nfrom langchain.tools import GooglePlacesTool # Or langchain_community.tools\\n\\n\\u200bGoogle Scholar\\nSearch academic papers. Requires google-search-results package and SerpApi key.\\npipuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_scholar import GoogleScholarQueryRun\\nfrom langchain_community.utilities.google_scholar import GoogleScholarAPIWrapper\\n\\n\\u200bGoogle Search\\nPerform web searches using Google Custom Search Engine (CSE). Requires GOOGLE_API_KEY and GOOGLE_CSE_ID.\\nInstall langchain-google-community:\\npipuvCopypip install langchain-google-community\\n\\nWrapper:\\nCopyfrom langchain_google_community import GoogleSearchAPIWrapper\\n\\nTools:\\nCopyfrom langchain_community.tools import GoogleSearchRun, GoogleSearchResults\\n\\nAgent Loading:\\nCopyfrom langchain_community.agent_toolkits.load_tools import load_tools\\ntools = load_tools([\"google-search\"])\\n\\nSee detailed notebook.\\n\\u200bGoogle Trends\\nQuery Google Trends data. Requires google-search-results package and SerpApi key.\\npipuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_trends import GoogleTrendsQueryRun\\nfrom langchain_community.utilities.google_trends import GoogleTrendsAPIWrapper\\n\\n\\u200bToolkits\\nCollections of tools for specific Google services.\\n\\u200bGmail\\n\\nGoogle Gmail is a free email service provided by Google.\\nThis toolkit works with emails through the Gmail API.\\n\\npipuvCopypip install langchain-google-community[gmail]\\n\\nSee usage example and authorization instructions.\\nCopy# Load the whole toolkit\\nfrom langchain_google_community import GmailToolkit\\n\\n# Or use individual tools\\nfrom langchain_google_community.gmail.create_draft import GmailCreateDraft\\nfrom langchain_google_community.gmail.get_message import GmailGetMessage\\nfrom langchain_google_community.gmail.get_thread import GmailGetThread\\nfrom langchain_google_community.gmail.search import GmailSearch\\nfrom langchain_google_community.gmail.send_message import GmailSendMessage\\n\\n\\u200bMCP Toolbox\\nMCP Toolbox provides a simple and efficient way to connect to your databases, including those on Google Cloud like Cloud SQL and AlloyDB. With MCP Toolbox, you can seamlessly integrate your database with LangChain to build powerful, data-driven applications.\\n\\u200bInstallation\\nTo get started, install the Toolbox server and client.\\nConfigure a tools.yaml to define your tools, and then execute toolbox to start the server:\\nCopytoolbox --tools-file \"tools.yaml\"\\n\\nThen, install the Toolbox client:\\npipuvCopypip install toolbox-langchain\\n\\n\\u200bGetting Started\\nHere is a quick example of how to use MCP Toolbox to connect to your database:\\nCopyfrom toolbox_langchain import ToolboxClient\\n\\nasync with ToolboxClient(\"http://127.0.0.1:5000\") as client:\\n\\n    tools = client.load_toolset()\\n\\nSee usage example and setup instructions.\\n\\u200bCallbacks\\nTrack LLM/Chat model usage.\\n\\u200bVertex AI callback handler\\n\\nCallback Handler that tracks VertexAI usage info.\\n\\nRequires langchain-google-vertexai.\\nCopyfrom langchain_google_vertexai.callbacks import VertexAICallbackHandler\\n\\n\\u200bEvaluators\\nEvaluate model outputs using Vertex AI.\\nRequires langchain-google-vertexai.\\n\\u200bVertexPairWiseStringEvaluator\\n\\nPair-wise evaluation using Vertex AI models.\\n\\nCopyfrom langchain_google_vertexai.evaluators.evaluation import VertexPairWiseStringEvaluator\\n\\n\\u200bVertexStringEvaluator\\n\\nEvaluate a single prediction string using Vertex AI models.\\n\\nCopy# Note: Original doc listed VertexPairWiseStringEvaluator twice. Assuming this class exists.\\nfrom langchain_google_vertexai.evaluators.evaluation import VertexStringEvaluator # Verify class name if needed\\n\\n\\u200bOther Google Products\\nIntegrations with various Google services beyond the core Cloud Platform.\\n\\u200bDocument Loaders\\n\\u200bGoogle Drive\\n\\nGoogle Drive file storage. Currently supports Google Docs.\\n\\nInstall with Drive dependencies:\\npipuvCopypip install langchain-google-community[drive]\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_google_community import GoogleDriveLoader\\n\\n\\u200bVector Stores\\n\\u200bScaNN (Local Index)\\n\\nGoogle ScaNN\\n(Scalable Nearest Neighbors) is a python package.\\nScaNN is a method for efficient vector similarity search at scale.\\n\\n\\nScaNN includes search space pruning and quantization for Maximum Inner\\nProduct Search and also supports other distance functions such as\\nEuclidean distance. The implementation is optimized for x86 processors\\nwith AVX2 support. See its Google Research github\\nfor more details.\\n\\nInstall the scann package:\\npipuvCopypip install scann langchain-community # Requires langchain-community\\n\\nSee a usage example.\\nCopyfrom langchain_community.vectorstores import ScaNN\\n\\n\\u200bRetrievers\\n\\u200bGoogle Drive\\nRetrieve documents from Google Drive.\\nInstall required packages:\\npipuvCopypip install google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-googledrive\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_googledrive.retrievers import GoogleDriveRetriever\\n\\n\\u200bTools\\n\\u200bGoogle Drive\\nTools for interacting with Google Drive.\\nInstall required packages:\\npipuvCopypip install google-api-python-client google-auth-httplib2 google-auth-oauthlib langchain-googledrive\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_googledrive.utilities.google_drive import GoogleDriveAPIWrapper\\nfrom langchain_googledrive.tools.google_drive.tool import GoogleDriveSearchTool\\n\\n\\u200bGoogle Finance\\nQuery financial data. Requires google-search-results package and SerpApi key.\\npipuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_finance import GoogleFinanceQueryRun\\nfrom langchain_community.utilities.google_finance import GoogleFinanceAPIWrapper\\n\\n\\u200bGoogle Jobs\\nQuery job listings. Requires google-search-results package and SerpApi key.\\npipuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_jobs import GoogleJobsQueryRun\\n# Note: Utilities might be shared, e.g., GoogleFinanceAPIWrapper was listed, verify correct utility\\n# from langchain_community.utilities.google_jobs import GoogleJobsAPIWrapper # If exists\\n\\n\\u200bGoogle Lens\\nPerform visual searches. Requires google-search-results package and SerpApi key.\\nuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_lens import GoogleLensQueryRun\\nfrom langchain_community.utilities.google_lens import GoogleLensAPIWrapper\\n\\n\\u200bGoogle Places\\nSearch for places information. Requires googlemaps package and a Google Maps API key.\\npipuvCopypip install googlemaps langchain # Requires base langchain\\n\\nSee usage example and authorization instructions.\\nCopy# Note: GooglePlacesTool might be in langchain or langchain_community depending on version\\nfrom langchain.tools import GooglePlacesTool # Or langchain_community.tools\\n\\n\\u200bGoogle Scholar\\nSearch academic papers. Requires google-search-results package and SerpApi key.\\nuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_scholar import GoogleScholarQueryRun\\nfrom langchain_community.utilities.google_scholar import GoogleScholarAPIWrapper\\n\\n\\u200bGoogle Search\\nPerform web searches using Google Custom Search Engine (CSE). Requires GOOGLE_API_KEY and GOOGLE_CSE_ID.\\nInstall langchain-google-community:\\npipuvCopypip install langchain-google-community\\n\\nWrapper:\\nCopyfrom langchain_google_community import GoogleSearchAPIWrapper\\n\\nTools:\\nCopyfrom langchain_community.tools import GoogleSearchRun, GoogleSearchResults\\n\\nAgent Loading:\\nCopyfrom langchain_community.agent_toolkits.load_tools import load_tools\\ntools = load_tools([\"google-search\"])\\n\\nSee detailed notebook.\\n\\u200bGoogle Trends\\nQuery Google Trends data. Requires google-search-results package and SerpApi key.\\npipuvCopypip install google-search-results langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.tools.google_trends import GoogleTrendsQueryRun\\nfrom langchain_community.utilities.google_trends import GoogleTrendsAPIWrapper\\n\\n\\u200bToolkits\\n\\u200bGmail\\n\\nGoogle Gmail is a free email service provided by Google.\\nThis toolkit works with emails through the Gmail API.\\n\\npipuvCopypip install langchain-google-community[gmail]\\n\\nSee usage example and authorization instructions.\\nCopy# Load the whole toolkit\\nfrom langchain_google_community import GmailToolkit\\n\\n# Or use individual tools\\nfrom langchain_google_community.gmail.create_draft import GmailCreateDraft\\nfrom langchain_google_community.gmail.get_message import GmailGetMessage\\nfrom langchain_google_community.gmail.get_thread import GmailGetThread\\nfrom langchain_google_community.gmail.search import GmailSearch\\nfrom langchain_google_community.gmail.send_message import GmailSendMessage\\n\\n\\u200bChat Loaders\\n\\u200bGmail\\n\\nLoad chat history from Gmail threads.\\n\\nInstall with Gmail dependencies:\\npipuvCopypip install langchain-google-community[gmail]\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_google_community import GMailLoader\\n\\n\\u200b3rd Party Integrations\\nAccess Google services via third-party APIs.\\n\\u200bSearchApi\\n\\nSearchApi provides API access to Google search, YouTube, etc. Requires langchain-community.\\n\\nSee usage examples and authorization instructions.\\nCopyfrom langchain_community.utilities import SearchApiAPIWrapper\\n\\n\\u200bSerpApi\\n\\nSerpApi provides API access to Google search results. Requires langchain-community.\\n\\nSee a usage example and authorization instructions.\\nCopyfrom langchain_community.utilities import SerpAPIWrapper\\n\\n\\u200bSerper.dev\\n\\nGoogle Serper provides API access to Google search results. Requires langchain-community.\\n\\nSee a usage example and authorization instructions.\\nCopyfrom langchain_community.utilities import GoogleSerperAPIWrapper\\n\\n\\u200bYouTube\\n\\u200bYouTube Search Tool\\n\\nSearch YouTube videos without the official API. Requires youtube_search package.\\n\\npipuvCopypip install youtube_search langchain # Requires base langchain\\n\\nSee a usage example.\\nCopy# Note: YouTubeSearchTool might be in langchain or langchain_community\\nfrom langchain.tools import YouTubeSearchTool # Or langchain_community.tools\\n\\n\\u200bYouTube Audio Loader\\nDownload audio from YouTube videos. Requires yt_dlp, pydub, librosa.\\nuvCopypip install yt_dlp pydub librosa langchain-community # Requires langchain-community\\n\\nSee usage example and authorization instructions.\\nCopyfrom langchain_community.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\\n# Often used with whisper parsers:\\n# from langchain_community.document_loaders.parsers import OpenAIWhisperParser, OpenAIWhisperParserLocal\\n\\n\\u200bYouTube Transcripts Loader\\nLoad video transcripts. Requires youtube-transcript-api.\\nuvCopypip install youtube-transcript-api langchain-community # Requires langchain-community\\n\\nSee a usage example.\\nCopyfrom langchain_community.document_loaders import YoutubeLoader\\nWas this page helpful?YesNoSuggest editsChatAnthropicChatGoogleGenerativeAIAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "## Single webpage loader\n",
    "URL = \"https://docs.langchain.com/oss/python/integrations/providers/google#document-loaders\"\n",
    "webLoader = WebBaseLoader(URL)\n",
    "all_webpage_contents = webLoader.load()\n",
    "\n",
    "# Show the content of the webpage\n",
    "all_webpage_contents[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ed6fc",
   "metadata": {},
   "source": [
    "## Concurrent and Multiple webpage loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "980a41dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content from URL 1:\n",
      "ComponentsDocument loadersWebBaseLoaderOn this pageWebBaseLoader\n",
      "This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.\n",
      "If you don't want to worry about website crawling, bypassing JS-blocking sites, and data cleaning, consider using FireCrawlLoader or the faster option SpiderLoader.\n",
      "Overview​\n",
      "Integration details​\n",
      "\n",
      "TODO: Fill in table features.\n",
      "TODO: Remove JS support link if not relevant, otherwise ensure link is correct.\n",
      "TODO: Make sure API reference links are correct.\n",
      "\n",
      "ClassPackageLocalSerializableJS supportWebBaseLoaderlangchain-community✅❌❌\n",
      "Loader features​\n",
      "SourceDocument Lazy LoadingNative Async SupportWebBaseLoader✅✅\n",
      "Setup​\n",
      "Credentials​\n",
      "WebBaseLoader does not require any credentials.\n",
      "Installation​\n",
      "To use the WebBaseLoader you first need to install the langchain-community python package.\n",
      "%pip install -qU langchain-community beautifulsoup4\n",
      "Initialization​\n",
      "Now we can instantiate our model object and load documents:\n",
      "from langchain_community.document_loaders import WebBaseLoaderloader = WebBaseLoader(\"https://www.example.com/\")\n",
      "To bypass SSL verification errors during fetching, you can set the \"verify\" option:\n",
      "loader.requests_kwargs = {'verify':False}\n",
      "Initialization with multiple pages​\n",
      "You can also pass in a list of pages to load from.\n",
      "loader_multiple_pages = WebBaseLoader(    [\"https://www.example.com/\", \"https://google.com\"])\n",
      "Load​\n",
      "docs = loader.load()docs[0]\n",
      "Document(metadata={'source': 'https://www.example.com/', 'title': 'Example Domain', 'language': 'No language found.'}, page_content='\\n\\n\\nExample Domain\\n\\n\\n\\n\\n\\n\\n\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...\\n\\n\\n\\n')\n",
      "print(docs[0].metadata)\n",
      "{'source': 'https://www.example.com/', 'title': 'Example Domain', 'language': 'No language found.'}\n",
      "Load multiple urls concurrently​\n",
      "You can speed up the scraping process by scraping and parsing multiple urls concurrently.\n",
      "There are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren't concerned about being a good citizen, or you control the server you are scraping and don't care about load, you can change the requests_per_second parameter to increase the max concurrent requests.  Note, while this will speed up the scraping process, but may cause the server to block you.  Be careful!\n",
      "%pip install -qU  nest_asyncio# fixes a bug with asyncio and jupyterimport nest_asyncionest_asyncio.apply()\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "loader = WebBaseLoader([\"https://www.example.com/\", \"https://google.com\"])loader.requests_per_second = 1docs = loader.aload()docs\n",
      "Fetching pages: 100%|###########################################################################| 2/2 [00:00<00:00,  8.28it/s]\n",
      "[Document(metadata={'source': 'https://www.example.com/', 'title': 'Example Domain', 'language': 'No language found.'}, page_content='\\n\\n\\nExample Domain\\n\\n\\n\\n\\n\\n\\n\\nExample Domain\\nThis domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.\\nMore information...\\n\\n\\n\\n'), Document(metadata={'source': 'https://google.com', 'title': 'Google', 'description': \"Search the world's information, including webpages, images, videos and more. Google has many special features to help you find exactly what you're looking for.\", 'language': 'en'}, page_content='GoogleSearch Images Maps Play YouTube News Gmail Drive More »Web History | Settings | Sign in\\xa0Advanced search5 ways Gemini can help during the HolidaysAdvertisingBusiness SolutionsAbout Google© 2024 - Privacy - Terms  ')]\n",
      "Loading a xml file, or using a different BeautifulSoup parser​\n",
      "You can also look at SitemapLoader for an example of how to load a sitemap file, which is an example of using this feature.\n",
      "loader = WebBaseLoader(    \"https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\")loader.default_parser = \"xml\"docs = loader.load()docs\n",
      "[Document(metadata={'source': 'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml'}, page_content='\\n\\n10\\nEnergy\\n3\\n2018-01-01\\n2018-01-01\\nfalse\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\nÂ§ 431.86\\nSection Â§ 431.86\\n\\nEnergy\\nDEPARTMENT OF ENERGY\\nENERGY CONSERVATION\\nENERGY EFFICIENCY PROGRAM FOR CERTAIN COMMERCIAL AND INDUSTRIAL EQUIPMENT\\nCommercial Packaged Boilers\\nTest Procedures\\n\\n\\n\\n\\n§\\u2009431.86\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\n(a) Scope. This section provides test procedures, pursuant to the Energy Policy and Conservation Act (EPCA), as amended, which must be followed for measuring the combustion efficiency and/or thermal efficiency of a gas- or oil-fired commercial packaged boiler.\\n(b) Testing and Calculations. Determine the thermal efficiency or combustion efficiency of commercial packaged boilers by conducting the appropriate test procedure(s) indicated in Table 1 of this section.\\n\\nTable 1—Test Requirements for Commercial Packaged Boiler Equipment Classes\\n\\nEquipment category\\nSubcategory\\nCertified rated inputBtu/h\\n\\nStandards efficiency metric(§\\u2009431.87)\\n\\nTest procedure(corresponding to\\nstandards efficiency\\nmetric required\\nby §\\u2009431.87)\\n\\n\\n\\nHot Water\\nGas-fired\\n≥300,000 and ≤2,500,000\\nThermal Efficiency\\nAppendix A, Section 2.\\n\\n\\nHot Water\\nGas-fired\\n>2,500,000\\nCombustion Efficiency\\nAppendix A, Section 3.\\n\\n\\nHot Water\\nOil-fired\\n≥300,000 and ≤2,500,000\\nThermal Efficiency\\nAppendix A, Section 2.\\n\\n\\nHot Water\\nOil-fired\\n>2,500,000\\nCombustion Efficiency\\nAppendix A, Section 3.\\n\\n\\nSteam\\nGas-fired (all*)\\n≥300,000 and ≤2,500,000\\nThermal Efficiency\\nAppendix A, Section 2.\\n\\n\\nSteam\\nGas-fired (all*)\\n>2,500,000 and ≤5,000,000\\nThermal Efficiency\\nAppendix A, Section 2.\\n\\n\\n\\u2003\\n\\n>5,000,000\\nThermal Efficiency\\nAppendix A, Section 2.OR\\nAppendix A, Section 3 with Section 2.4.3.2.\\n\\n\\n\\nSteam\\nOil-fired\\n≥300,000 and ≤2,500,000\\nThermal Efficiency\\nAppendix A, Section 2.\\n\\n\\nSteam\\nOil-fired\\n>2,500,000 and ≤5,000,000\\nThermal Efficiency\\nAppendix A, Section 2.\\n\\n\\n\\u2003\\n\\n>5,000,000\\nThermal Efficiency\\nAppendix A, Section 2.OR\\nAppendix A, Section 3. with Section 2.4.3.2.\\n\\n\\n\\n*\\u2009Equipment classes for commercial packaged boilers as of July 22, 2009 (74 FR 36355) distinguish between gas-fired natural draft and all other gas-fired (except natural draft).\\n\\n(c) Field Tests. The field test provisions of appendix A may be used only to test a unit of commercial packaged boiler with rated input greater than 5,000,000 Btu/h.\\n[81 FR 89305, Dec. 9, 2016]\\n\\n\\nEnergy Efficiency Standards\\n\\n')]\n",
      "Lazy Load​\n",
      "You can use lazy loading to only load one page at a time in order to minimize memory requirements.\n",
      "pages = []for doc in loader.lazy_load():    pages.append(doc)print(pages[0].page_content[:100])print(pages[0].metadata)\n",
      "10Energy32018-01-012018-01-01falseUniform test method for the measurement of energy efficien{'source': 'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml'}\n",
      "Async​\n",
      "pages = []async for doc in loader.alazy_load():    pages.append(doc)print(pages[0].page_content[:100])print(pages[0].metadata)\n",
      "Fetching pages: 100%|###########################################################################| 1/1 [00:00<00:00, 10.51it/s]``````output10Energy32018-01-012018-01-01falseUniform test method for the measurement of energy efficien{'source': 'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml'}\n",
      "Using proxies​\n",
      "Sometimes you might need to use proxies to get around IP blocks. You can pass in a dictionary of proxies to the loader (and requests underneath) to use them.\n",
      "loader = WebBaseLoader(    \"https://www.walmart.com/search?q=parrots\",    proxies={        \"http\": \"http://{username}:{password}:@proxy.service.com:6666/\",        \"https\": \"https://{username}:{password}:@proxy.service.com:6666/\",    },)docs = loader.load()\n",
      "API reference​\n",
      "For detailed documentation of all WebBaseLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html\n",
      "Related​\n",
      "\n",
      "Document loader conceptual guide\n",
      "Document loader how-to guides\n",
      "Edit this pagePreviousWeatherNextWhatsApp ChatOverviewIntegration detailsLoader featuresSetupCredentialsInstallationInitializationInitialization with multiple pagesLoadLoad multiple urls concurrentlyLoading a xml file, or using a different BeautifulSoup parserLazy LoadAsyncUsing proxiesAPI referenceRelated...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "URLs = [\n",
    "    \"https://python.langchain.com/docs/integrations/document_loaders/web_base/\"\n",
    "]\n",
    "\n",
    "\n",
    "def load_multiple_webpages(urls):\n",
    "    webLoader = WebBaseLoader(urls, bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "        class_=(\"container padding-top--md padding-bottom--lg\")\n",
    "    )))\n",
    "\n",
    "    # request per second\n",
    "    webLoader.requests_per_second = 2\n",
    "    # async loading webpages\n",
    "    all_webpage_contents = webLoader.load()\n",
    "\n",
    "    def show_content():\n",
    "        for i, content in enumerate(all_webpage_contents):\n",
    "            print(\n",
    "                f\"Content from URL {i+1}:\\n{content.page_content}...\\n\")\n",
    "\n",
    "    show_content()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_multiple_webpages(urls=URLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debdb36a",
   "metadata": {},
   "source": [
    "## Text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "# provide list of string to split\n",
    "all_chunks = text_splitter.create_documents([doc.page_content for doc in loadObj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4794863",
   "metadata": {},
   "source": [
    "## HTML Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8509ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<body><noscript>You need to enable JavaScript to run this app.</noscript><div id=\"root\"><div class=\"Dashboard fullscreen dark\"><div class=\"Background\"><div class=\"Unsplash fullscreen\"><div class=\"fullscreen\" style=\"opacity: 1; transition: opacity 150ms ease-in-out;\"><div class=\"image fullscreen\" style=\"background-image: url(&quot;https://images.unsplash.com/photo-1492136344046-866c85e0bf04?ixid=M3wxMTI1OHwwfDF8cmFuZG9tfHx8fHx8fHx8MTc1OTQ3MDcxMnw&amp;ixlib=rb-4.1.0&amp;q=85&amp;w=1920&quot;); opacity: 0.8;\"></div></div><div class=\"credit\"><div class=\"photo\"><a href=\"https://unsplash.com/photos/eiffel-tower-paris-NT1mJPgni6A?utm_source=Start&amp;utm_medium=referral&amp;utm_campaign=api-credit\" rel=\"noopener noreferrer\">Photo</a>, <a href=\"https://unsplash.com/@jadlimcaco?utm_source=Start&amp;utm_medium=referral&amp;utm_campaign=api-credit\" rel=\"noopener noreferrer\">Jad Limcaco</a>, <a href=\"https://unsplash.com/?utm_source=Start&amp;utm_medium=referral&amp;utm_campaign=api-credit\" rel=\"noopener noreferrer\">Unsplash</a></div><div class=\"controls\"><a class=\"\"><i><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><line x1=\"19\" y1=\"12\" x2=\"5\" y2=\"12\"></line><polyline points=\"12 19 5 12 12 5\"></polyline></svg></i></a> <a><i><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><rect x=\"6\" y=\"4\" width=\"4\" height=\"16\"></rect><rect x=\"14\" y=\"4\" width=\"4\" height=\"16\"></rect></svg></i></a> <a class=\"\"><i><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><line x1=\"5\" y1=\"12\" x2=\"19\" y2=\"12\"></line><polyline points=\"12 5 19 12 12 19\"></polyline></svg></i></a></div><div class=\"location\"></div></div></div></div><div class=\"Widgets fullscreen\"><div class=\"container\"><div class=\"Slot middleCentre\"><div class=\"Widget \" style=\"font-size: 24px;\"><div class=\"Time\"><div class=\"Time Digital\"><h1>19:40</h1></div></div></div><div class=\"Widget \" style=\"font-size: 24px;\"><div class=\"Greeting\"><h2>Good evening</h2></div></div></div></div></div><div class=\"Overlay\"><a title=\"Customise Tabliss (S)\"><i><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><circle cx=\"12\" cy=\"12\" r=\"3\"></circle><path d=\"M19.4 15a1.65 1.65 0 0 0 .33 1.82l.06.06a2 2 0 0 1 0 2.83 2 2 0 0 1-2.83 0l-.06-.06a1.65 1.65 0 0 0-1.82-.33 1.65 1.65 0 0 0-1 1.51V21a2 2 0 0 1-2 2 2 2 0 0 1-2-2v-.09A1.65 1.65 0 0 0 9 19.4a1.65 1.65 0 0 0-1.82.33l-.06.06a2 2 0 0 1-2.83 0 2 2 0 0 1 0-2.83l.06-.06a1.65 1.65 0 0 0 .33-1.82 1.65 1.65 0 0 0-1.51-1H3a2 2 0 0 1-2-2 2 2 0 0 1 2-2h.09A1.65 1.65 0 0 0 4.6 9a1.65 1.65 0 0 0-.33-1.82l-.06-.06a2 2 0 0 1 0-2.83 2 2 0 0 1 2.83 0l.06.06a1.65 1.65 0 0 0 1.82.33H9a1.65 1.65 0 0 0 1-1.51V3a2 2 0 0 1 2-2 2 2 0 0 1 2 2v.09a1.65 1.65 0 0 0 1 1.51 1.65 1.65 0 0 0 1.82-.33l.06-.06a2 2 0 0 1 2.83 0 2 2 0 0 1 0 2.83l-.06.06a1.65 1.65 0 0 0-.33 1.82V9a1.65 1.65 0 0 0 1.51 1H21a2 2 0 0 1 2 2 2 2 0 0 1-2 2h-.09a1.65 1.65 0 0 0-1.51 1z\"></path></svg></i></a><a class=\"on-hover\" title=\"Toggle widgets (W)\"><i><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z\"></path><circle cx=\"12\" cy=\"12\" r=\"3\"></circle></svg></i></a><a class=\"on-hover\" title=\"Toggle fullscreen (F)\"><i><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><polyline points=\"15 3 21 3 21 9\"></polyline><polyline points=\"9 21 3 21 3 15\"></polyline><line x1=\"21\" y1=\"3\" x2=\"14\" y2=\"10\"></line><line x1=\"3\" y1=\"21\" x2=\"10\" y2=\"14\"></line></svg></i></a></div></div></div></body>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c65a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Main\"),\n",
    "    (\"h2\", \"Second Main\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "documents = html_splitter.split_text(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84392ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='You need to enable JavaScript to run this app.  \\n, ,  \\nPhoto  \\nJad Limcaco  \\nUnsplash'),\n",
       " Document(metadata={'Main': '19:40'}, page_content='19:40'),\n",
       " Document(metadata={'Main': '19:40', 'Second Main': 'Good evening'}, page_content='Good evening')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f24f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
